#+TITLE: Notes from Can Programming Be Liberated from the von Neumann Style - John Backus
#+EMAIL: balaji AT balajisivaraman DOT com
#+AUTHOR: Balaji Sivaraman
#+LANGUAGE: en
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage{amssymb, amsmath, mathtools, fullpage, fontspec}
#+LATEX_HEADER: \renewcommand*{\familydefault}{\sfdefault}
#+LATEX_HEADER: \setsansfont{Verdana}
#+LATEX: \newpage
* Conventional languages: fat and flabby
** Five Hundred or Thousand page manuals
** New fashionable features (strong typing, structured control statements) but don't make programming cheaper to justify the cost of learning them
** Large increases in size only bring small increases in power (hence, popularity of small langs like Pascal)
** New methodolgy is needed to help us think about programs
* Models of Computing Systems
** Underlying every language is a model of a computing system that its programs control (pure abstractions, hardware or compiling/interpretive programs)
** Criteria for Models
*** Foundations - Is there an elegant, concise description of the model?
*** History Sensitivity - Does the model include a notion of storage, so that one program can save info that affects a later program?
*** Types of semantics - Does the program transform states until a terminal state is reached? Can it be reduced to yield smaller programs, the smallest of which is the normal form?
*** Clarity and conceptual usefulness of programs - Are the programs a clear expression of a model of computation? Do they help make it easier to formulate and reason about processes?
** Model Classification
*** Simple Operational Models - Turing machines, various automata etc. First 3 properties met, but programs are clear and conceptually not helpful.
*** Applicative Models - Lambda Calculus, Curry's system of combinators, pure Lisp. No storage in the purest form. Programs can be reduced, but no state. Programs can be clear and conceptually helpful.
*** Von Neumann Models - Von Neumann Computers, conventional prog langs. Foundations bulky and not useful. Have state and program reduction. Programs are moderately clear but not conceptually helpful.
* Von Neumann Computers
** Every VNC has 3 parts: a CPU, a store and a tube to transmit a single word b/w the CPU to the store (and send an address to the store).
** Backus calls this tube the "Von Neumann Bottleneck".
** The task of the program to change the contents of the store in a major way. The only way this can be achieved is by sending single words through the tube, hence the name.
** A large part of the traffic in the tube is not useful data, but merely names of data or operations to the CPU.
** Before a word can be sent through the tube, its address must be in the CPU. Hence, it must be sent through the tube or generated by some CPU operation. This is an endless cycle.
** Not only is the tube a literal bottleneck, it's also an intellectual bottleneck that has kept us tied to word-at-a-time thinking, instead of making us think about larger conceptual problems at hand.
* Von Neumann Languages
** Conventional programming languages are basically high-level, complex versions of the VNC.
** Variables imitate the storage cell. Control statements elaborate its jump and test instructions. Assignment statements imitate fetching, storing and arithmetic.
** The assignment statement is the Von Neumann bottleneck of programming languages.
** A typical program has at its center a number of assignment statements containing subscripted variables, each of which produces a one-word result.
** The assignment statement splits the world of the programmer into two worlds:
*** The right side of the statement is an expression that has useful algebraic properties (usually destroyed because of side-effects)
*** The second world is the world of statements. The first is the assignment statement. All other statements exist in the language to make it possible to perform a computation to serve the assignment statement.
*** World of statements is a disorderly one, which structured programming tries to organize into a coherent one.
** Applicative systems lack of storage don't make them amiable to developing computers. Their core operation is the substitution operation, which is super-powerful.
** Applicative languages such as Lisp also tend to have extensions that make them von Neumann like, only to result in a lot of confusion.
* Comparison of Von Neumann and Functional Programs
** Go to paper Section 5.1 for a beautiful description of what's wrong with a Von Neumann program
** Go to paper Section 5.2 for a beautiful description of what's great about the functional program
* Language Frameworks vs Changeable Parts
** Framework - Rules of the system (the FOR statement in Algol)
** Changeable Parts - Library procedures and user defined functions
** Framework describes the fixed features and provides a general environment for its changeable features
** Suppose an imaginary language had a small framework that could accommodate a huge number of changeable parts: This would be great
** Instead Von Neumann Languages have an immense framework with very limited changeable parts.
** Two problems of Von Neumann Languages
*** Word at a Time Thinking - Stipulates that words flow back and forth to the state, just like flowing through the actual tube.
*** So the language must have semantics slowly coupled with this state manipulation.
*** Every detail of every feature must be built into the state and its transition rules.
*** Many features are needed to prop-up the word at at time style. This results in a rigid and enormous framework.
* Changeable Parts and Combining Forms
** Second problem of VN langs is that their changeable parts have very little expressive power.
** If the designer knew that the complicated features could be added later, they won't be so eager to build them into the framework.
** VN langs provide only primitive combining forms and the framework itself presents obstacles to their use.
** The two worlds are problematic. Functional forms naturally fit into the world of expressions. But no matter how powerful they are, they must produce a one-word result.
** Second obstacle is the use of elaborate naming conventions: variables, subscripted variables, file names, pointers, call-by-name, call-by-value etc. all require a complex mechanism to be formally interpreted.
* APL vs Word at a Time Programming
** APL showed that there is an alternative to word at a time and lambda expressions.
** But it still splits the world into one of statements and one of expressions.
** APL semantics still coupled to state. So the framework still has the complexity and rigidity of VN langs.
* VN Langs Lack Useful Mathematical Properties
** VN langs have no properties that are helpful in reasoninga about them, and many that aren't (side effects, aliasing).
** Denotational semantics applied to applicative programs provide tools and helps in proving properties of the programs.
** When applied to a VN lang, it provides a precise semantic description and helps in identifying trouble spots in the language. They result in a bewildering mess that are only slightly less complex than the reference manual of the language.
** Axiomatic semantics precisely restates the inelegant properties of Von Neumann programs (transformations on state as transformations on predicates).
** Proofs about programs use the language of logic, not the language of programming. They describe a program, but cannot invoke them. Many ordinary proofs are derived from algebraic methods.
* Alternatives to VN Langs
** Systems that want to be history sensitive must have state-transition semantics. This does not mean that every computation must depend on a complex state.
** Backus' approach involves four elements:
*** Functional style without variables
*** Algebra of functional programs - Algebra can be compared with classical applicative algebras of Church and Curry.
*** A formal functional programming system - FFP system is a formal description of the above informal FP system
*** Applicative state transition systems - Above FFP system can be used as the basis for AST systems
* FP Systems
** Founded on the use of a simple set of combining forms called functional forms. There is no substitution and no variables.
** All functions are of a sinle type: they map objects into objects and take a single parameter.
** In contrast, a lambda calculus system describes a language that can be used to specify all programs. With unrestricted freedom, comes chaos. (Think Von Neumann languages with unrestricted control statements.)
** Description
*** a set O of objects
*** a set F of functions that map objects into objects
*** an operation, application
*** a set F of functional forms that let you combine functions or objects
*** a set D of definitions that define some functions in F and assign names to them
** The primary limitation of FP systems is that they are not history sensitive. This can be alleviated by having a FFP system.
* The Algebra of Programs for FP systems
** This needs to be read at a later point in time.
* Formal Systems for FP
** FP systems are limited by its set of functional forms. If its empty, all you have are primitive functions.
** In FFP systems, objects are used to "represent" functions in a systematic way.
** Look at syntax definition in the paper. It's pretty well-defined.
** Every FFP expression e has a meaning denoted by Micro-E.
** Function application is similar to FP systems, but in FFP, functions are represented by objects.
** The association between objects and the functions they represent is given by the representation function of the FFP system.
** Both P and Micro belong to the description of the system, and not the system itself.
** You get a function called apply in FFP system, which is not possible in an FP system.
** Metacomposition allows defining new functional forms in a great variety of ways.
** Cells, fetching and storing
*** A new object called cell, and new functional forms called fetch and store.
* Applicative State Transition Systems
** Limitations of Algol
*** An Algol program is a sequence of statements, each representing a transformation of the Algol state, which is a complex repository of information about the status of various stacks, pointers, and variable mappings.
*** Thus Algol statements are not expressions representing state-to-state functions that are built up by the use of orderly combining forms from simpler state-to-state functions. Instead they are complex messages with context-dependent parts that nibble away at the state.
*** We want a computing system whose semantics does not depend on a host of baroque protocols for communicating with the state, and we want to be able to make large transformations in the state by the application of general functions.
** Structure of FFP
*** In contrast, FFP systems has two protocols for getting info from the state:
**** Get the definition of a function to be applied
**** Get the whole state itsel
*** There is one protocol for changing the state: compute the new state by function application
*** Besides the above, the state does not change during function application. Instead, the result of a computation is output and a new state. (State Monad anyone?)
*** Thus the structure of AST systems avoids the complexity and restrictions of the von Neumann state (with its communications protocols) while achieving greater power and freedom in a radically different and simpler framework.
** Structure of AST
*** Three components:
**** An applicative subsystem, FFP in our case
**** A state D that is the set of definitions of the applicative subsystem
**** A set of transition rules that describes how inputs are transformed into outputs and how the state D is changed
